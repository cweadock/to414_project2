---
title: "Project 2"
author: "Kate Sawdey, Claire Weadock, Olivia Caponecchi, Michael Zuckerman, Anna Dolce, Rubens Mondi"
date: "3/5/2023"
output:
  html_document:
    toc: true
    theme: readable
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Executive Summary

[insert exec summary]

# Intro

[insert intro]

## Downloading and Prepping the Data

```{r}
#Downloading and Prepping the Data
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
summary(tele)

#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL

# Deleting the column X
tele$X <- NULL

# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL


#banding age into generational categories
tele$age_range <- ifelse(tele$age <= 25 , "Under 25" ,
                        ifelse(tele$age > 25 & tele$age <= 42, "26-42", 
                               ifelse(tele$age > 42 & tele$age <= 58, "43-58", "Over 58")))

tele$age <- NULL


```



## Getting Data Ready for Analysis

```{r}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

telemm <- as.data.frame(model.matrix(~.-1,tele))
str(telemm)

# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
tele_random <- telemm[sample(nrow(telemm)),]

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything 
tele_norm <- as.data.frame(lapply(tele_random, normalize))
```


## Getting Train and Test Samples

```{r}
# Selects 10000 random rows for test data
set.seed(12345)
test_set <- sample(1:nrow(tele_norm), 10000) 
# Depending on R-version and computer, different rows may be selected. 
# If that happens, results are different. 

log_train <- tele_norm[ -test_set, ]
log_test <- tele_norm[ test_set , ]

# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, -match("yyes",names(tele_norm))]
tele_test <- tele_norm[test_set, -match("yyes",names(tele_norm))]

#Now the response (aka Labels) - only the yyes column
tele_train_labels <- tele_norm[-test_set, "yyes"]
tele_test_labels <- tele_norm[test_set, "yyes"]

```

> Now you are ready to build your ANN model. Feel free to modify the data load, cleaning and preparation code above as per your preference.


# Logistic Regression

```{r log model main effects}

log_model_ME <- glm(yyes ~ . , data = log_train , family = "binomial")
summary(log_model_ME)

log_pred_ME <- predict(log_model_ME , log_test)

library(caret)
postResample(log_pred_ME , log_test$yyes)

```


```{r}


#insert interactions




```



# KNN Model

```{r}

library(class)

knn_model <- knn(tele_train , tele_test , cl = tele_train_labels, k = 10)

library(gmodels)

CrossTable(knn_model , tele_test_labels)

```

```{r probably meet}


#tele_zscore <- as.data.frame(model.matrix(~.-1,tele))

#tele_train_zscore <- tele_zscore[-test_set, -match("yyes",names(tele_norm))]
#tele_test_zscore <- tele_zscore[test_set, -match("yyes",names(tele_norm))]

#tele_train_labels_zscore <- tele_norm[-test_set, "yyes"]
#tele_test_labels_zscore <- tele_norm[test_set, "yyes"]


#knn_zscore <- knn(tele_train_zscore, tele_test_zscore, cl = tele_train_labels_zscore, k = 20)


#CrossTable(knn_zscore , tele_test_labels_zscore)

```





# ANN Model


# Combining Models Together


# Results and Analysis


# Conclusion