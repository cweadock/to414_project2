---
title: "Project 2"
author: "Kate Sawdey, Claire Weadock, Olivia Caponecchi, Michael Zuckerman, Anna Dolce, Rubens Mondi"
date: "3/5/2023"
output:
  html_document:
    toc: true
    theme: readable
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Delegating remaining work:

- find log reg threshold: **Rubens**
- best k value for knn(add code for optimization): **claire**
- hidden value for ann: **kate**
- run models and save to rds: **Kate**
- intro: **anna and liv**
- exec summary: **anna and liv**
- conclusion: **mike**
- results & financial analysis: **mike**
- combine models: **kate**
- write explanations under headers explaining the code we did: **claire**


# Executive Summary

[insert exec summary]

# Intro

[insert intro]

- introduce problem and process to solve

- current success rate = 11.26%
- current profit = -13,348
- break even success rate = 16.667%


## Downloading and Prepping the Data

```{r}
#Downloading and Prepping the Data
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
summary(tele)

#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL

# Deleting the column X
tele$X <- NULL

# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL


#banding age into generational categories
#tele$age_range <- ifelse(tele$age <= 25 , "Under 25" ,
                        #ifelse(tele$age > 25 & tele$age <= 42, "26-42", 
                               #ifelse(tele$age > 42 & tele$age <= 58, "43-58", "Over 58")))

#tele$age <- NULL

summary(tele$y) # useful for calls and success rates and profits

```



## Getting Data Ready for Analysis

```{r}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

telemm <- as.data.frame(model.matrix(~.-1,tele))
str(telemm)

# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
tele_random <- telemm[sample(nrow(telemm)),]

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything 
tele_norm <- as.data.frame(lapply(tele_random, normalize))
```


## Getting Train and Test Samples

```{r}
# Selects 10000 random rows for test data
set.seed(12345)
test_set <- sample(1:nrow(tele_norm), 10000) 
# Depending on R-version and computer, different rows may be selected. 
# If that happens, results are different. 

log_train <- tele_norm[ -test_set, ]
log_test <- tele_norm[ test_set , ]

# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, -match("yyes",names(tele_norm))]
tele_test <- tele_norm[test_set, -match("yyes",names(tele_norm))]

#Now the response (aka Labels) - only the yyes column
tele_train_labels <- tele_norm[-test_set, "yyes"]
tele_test_labels <- tele_norm[test_set, "yyes"]

# can use write.csv to put all of our new data sets into seperate, cleaned csv
#write.csv(tele_train, "tele_train.csv")
```


# Logistic Regression

```{r log model main effects}

log_model_ME <- glm(yyes ~ . , data = log_train , family = "binomial")


#below is code prof gave if we want to do all interactions and step function but may not be worth it because regression not precise
#log_model_test <- glm(yyes ~ . + .*., data = log_train , family = "binomial")
#summary(log_model_test)

summary(log_model_ME)

log_pred_ME <- predict(log_model_ME , log_test , type = "response")

log_pred_ME_binary <- ifelse(log_pred_ME >= 0.3, 1, 0) # have to find the right threshold here; may be useful to find break even rates


library(caret)
confmat <- confusionMatrix(as.factor(log_pred_ME_binary) , as.factor(log_test$yyes), positive = "1")

confmat
outcome_weights <- matrix(
          c(0, 0,
          -1, 5),
          nrow = 2,
          byrow = TRUE
)

conf_mat_wg <- sum(confmat$table*outcome_weights)
str(conf_mat_wg)

outcome <- data.frame(threshold = numeric(), profit = numeric())


#We have created  a for loop that calculate the profit level for each threshold in the range from 0 to 1 with steps of 0.01. 

threshold_list <- seq(from = 0.01, to = 1, by = 0.01)
for (i in threshold_list) {
  log_pred_ME_binary <- ifelse(log_pred_ME >= i, 1, 0)
  confmat <- confusionMatrix(as.factor(log_pred_ME_binary) , as.factor(log_test$yyes), positive = "1")
  out <- sum(confmat$table*outcome_weights)
  nrow <- data.frame(threshold = i, profit = out)
  outcome <- rbind(outcome,nrow)
}
#the loop resulted in the outcome data-frame, which contain the bottom line profit for each threshold level. 
# We have build a line plot to visualize the result form the loop, from which is apparent that the optimal threshold resides between 0.15 and 0.25. As a matter of fact, a threshold of 0.19 return a profit of 2493 $, which is the highest possible. 
#NB. It is possible to take into account the opportunity cost of losing the call for which we predicted a negative outcome but which actually could have been resulted in a loan subscription. In that case we should adjust the outcome_weights matrix for a value x in c(0, x , -1, 5) that accounts for the opportunity cost (-5<x<0). 
outcome
ggplot(outcome, aes(x = threshold, y = profit)) + 
  geom_line() + 
  labs(x = "Threshold", y = "Profit", title = "Profit per Treshold level")

#With the optimal threshold value we have: 
log_pred_ME_binary <- ifelse(log_pred_ME >= 0.19, 1, 0)
opt_confmat <- confusionMatrix(as.factor(log_pred_ME_binary) , as.factor(log_test$yyes), positive = "1") 
opt_confmat #this is the confusion matrix before applying weights 

opt_conf_mat_wg <- confmat$table*outcome_weights 
opt_conf_mat_wg #this is the confusion matrix after applying the weights 
```




# KNN Model

```{r}

library(class)

knn_model <- knn(tele_train , tele_test , cl = tele_train_labels, k = 1) #still need to figure out best k

#saveRDS(knn_model, "testfile.rds")
# above is the example he gave to save the model to a file such that it doesnt run many times

library(gmodels)

CrossTable(knn_model , tele_test_labels)

```





# ANN Model

```{r ann 1 hidden, eval=FALSE}


library(neuralnet)
library(caret)

ann_model_1hidden <- neuralnet(yyes ~ . , data = log_train, hidden = 1)
saveRDS(ann_model_1hidden , "ann_1hidden.rds")

# do 1 hidden, then 5, then 20 if possible


```
```{r ann 5 hidden, eval=FALSE}

library(neuralnet)
library(caret)

ann_model_5hidden <- neuralnet(yyes ~ . , data = log_train, hidden = 5)
saveRDS(ann_model_5hidden , "ann_5hidden.rds")


```

```{r ann 20 hidden}

#library(neuralnet)
#library(caret)

#ann_model_20hidden <- neuralnet(yyes ~ . , data = log_train, hidden = 20)
#saveRDS(ann_model_20hidden , "ann_20hidden.rds")



```



# Combining Models Together


# Results and Analysis

we should look at the profit from each model individual and combined and compare to best


- make sure to talk about favoring false pos over false neg because get 6 in revenue compared to 1 cost

# Conclusion

