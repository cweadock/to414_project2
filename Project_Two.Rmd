---
title: "Project 2"
author: "Kate Sawdey, Claire Weadock, Olivia Caponecchi, Michael Zuckerman, Anna Dolce, Rubens Mondi"
date: "3/5/2023"
output:
  html_document:
    toc: true
    theme: readable
    highlight: tango
    code_folding: show
    number_sections: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Delegating remaining work:

- find log reg threshold: **Rubens**
- best k value for knn(add code for optimization): **claire**
- hidden value for ann: **kate**
- run models and save to rds: **Kate**
- intro: **anna and liv**
- exec summary: **anna and liv**
- conclusion: **mike**
- results & financial analysis: **mike**
- combine models: **kate**
- write explanations under headers explaining the code we did: **claire**


# Executive Summary

[insert exec summary]

# Intro

[insert intro]

- introduce problem and process to solve

- current success rate = 11.26%
- current profit = -13,348
- break even success rate = 16.667%


## Downloading and Prepping the Data

```{r}
#Downloading and Prepping the Data
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
summary(tele)

#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL

# Deleting the column X
tele$X <- NULL

# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL


#banding age into generational categories
#tele$age_range <- ifelse(tele$age <= 25 , "Under 25" ,
                        #ifelse(tele$age > 25 & tele$age <= 42, "26-42", 
                               #ifelse(tele$age > 42 & tele$age <= 58, "43-58", "Over 58")))

#tele$age <- NULL

summary(tele$y) # useful for calls and success rates and profits

```



## Getting Data Ready for Analysis

```{r}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

telemm <- as.data.frame(model.matrix(~.-1,tele))
str(telemm)

# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
tele_random <- telemm[sample(nrow(telemm)),]

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything 
tele_norm <- as.data.frame(lapply(tele_random, normalize))
```


## Getting Train and Test Samples

```{r}
# Selects 10000 random rows for test data
set.seed(12345)
test_set <- sample(1:nrow(tele_norm), 10000) 
# Depending on R-version and computer, different rows may be selected. 
# If that happens, results are different. 

# we only want the labels taken out of the data set for the knn model, the other two we can use a test/train break up with all variables included.
log_train <- tele_norm[ -test_set, ]
log_test <- tele_norm[ test_set , ]

# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, -match("yyes",names(tele_norm))]
tele_test <- tele_norm[test_set, -match("yyes",names(tele_norm))]

#Now the response (aka Labels) - only the yyes column
tele_train_labels <- tele_norm[-test_set, "yyes"]
tele_test_labels <- tele_norm[test_set, "yyes"]

# can use write.csv to put all of our new data sets into seperate, cleaned csv
#write.csv(tele_train, "tele_train.csv")
```


# Logistic Regression

```{r log model main effects}

log_model_ME <- glm(yyes ~ . , data = log_train , family = "binomial")


#below is code prof gave if we want to do all interactions and step function but may not be worth it because regression not precise
#log_model_test <- glm(yyes ~ . + .*., data = log_train , family = "binomial")
#summary(log_model_test)

summary(log_model_ME)

log_pred_ME <- predict(log_model_ME , log_test , type = "response")

log_pred_ME_binary <- ifelse(log_pred_ME >= 0.3, 1, 0) # have to find the right threshold here; may be useful to find break even rates


library(caret)
confmat <- confusionMatrix(as.factor(log_pred_ME_binary) , as.factor(log_test$yyes), positive = "1")

confmat
outcome_weights <- matrix(
          c(0, 0,
          -1, 5),
          nrow = 2,
          byrow = TRUE
)

conf_mat_wg <- sum(confmat$table*outcome_weights)
str(conf_mat_wg)

outcome <- data.frame(threshold = numeric(), profit = numeric())


#We have created  a for loop that calculate the profit level for each threshold in the range from 0 to 1 with steps of 0.01. 

threshold_list <- seq(from = 0.01, to = 1, by = 0.01)
for (i in threshold_list) {
  log_pred_ME_binary <- ifelse(log_pred_ME >= i, 1, 0)
  confmat <- confusionMatrix(as.factor(log_pred_ME_binary) , as.factor(log_test$yyes), positive = "1")
  out <- sum(confmat$table*outcome_weights)
  nrow <- data.frame(threshold = i, profit = out)
  outcome <- rbind(outcome,nrow)
}
#the loop resulted in the outcome data-frame, which contain the bottom line profit for each threshold level. 
# We have build a line plot to visualize the result form the loop, from which is apparent that the optimal threshold resides between 0.15 and 0.25. As a matter of fact, a threshold of 0.19 return a profit of 2493 $, which is the highest possible. 
#NB. It is possible to take into account the opportunity cost of losing the call for which we predicted a negative outcome but which actually could have been resulted in a loan subscription. In that case we should adjust the outcome_weights matrix for a value x in c(0, x , -1, 5) that accounts for the opportunity cost (-5<x<0). 
outcome
ggplot(outcome, aes(x = threshold, y = profit)) + 
  geom_line() + 
  labs(x = "Threshold", y = "Profit", title = "Profit per Treshold level")

#With the optimal threshold value we have: 
log_pred_ME_binary <- ifelse(log_pred_ME >= 0.19, 1, 0)
opt_confmat <- confusionMatrix(as.factor(log_pred_ME_binary) , as.factor(log_test$yyes), positive = "1") 
opt_confmat #this is the confusion matrix before applying weights 

opt_conf_mat_wg <- confmat$table*outcome_weights 
opt_conf_mat_wg #this is the confusion matrix after applying the weights 
```




# KNN Model

```{r}

library(class)

knn_model <- knn(tele_train , tele_test , cl = tele_train_labels, k = 1) #still need to figure out best k

#saveRDS(knn_model, "testfile.rds")
# above is the example he gave to save the model to a file such that it doesnt run many times

library(gmodels)

#d <- CrossTable(knn_model , tele_test_labels)

```


# Finding optimal k value based on model accuracy

```{r}
accuracies<- c()
for (i in 1:10){ 
    knn.mod <-  knn(train=tele_train, test=tele_test, cl=tele_train_labels, k=i)
    k.optm[i] <- 100 * sum(tele_test_labels == knn.mod)/NROW(tele_test_labels)
    k=i  
    accuracies <- append(accuracies, k.optm[i])
    cat(k,'=',k.optm[i],'\n')       # to print % accuracy 
}
```
```{r}
plot(accuracies, type = "o", xlab="k value", ylab = "Accuracy %")
```


# Finding financially optimal k value

```{r}
profits <- c()

for (i in 1:10){
  knn.mod2 <-  knn(train=tele_train, test=tele_test, cl=tele_train_labels, k=i)
  crosstab <- CrossTable(knn.mod2 , tele_test_labels, prop.r = FALSE, prop.c = FALSE, prop.t = FALSE, prop.chisq = FALSE)
  A <- crosstab$t['0','0']
  B <- crosstab$t['1','0']
  C <- crosstab$t['0','1']
  D <- crosstab$t['1','1']
  
  profit <- (A)-(5*B)-(C)+(5*D)
  profits <- append(profits, profit)
  
  cat('k =', i, 'then profit = $', profit, '\n')
}
```

```{r}
plot(profits, type = "o", xlab="k value", ylab = "Profit $")

```



# ANN Model

Per our discussion with Professor Kumar's, we attempted to run an ANN model on the data using 1, 5, and 20 as potential hidden values. In the first two code blocks below, you can see our code which runs an ANN model using both 1 and 5 for hidden values and saving them to RDS files respectively. However, due to the limited computing power of our personal laptops, we were unable to get an ANN model with hidden = 20 to run successfully. The code which we unsuccessfully attempted is also illustrated below in the third code block.

We chose to save each model into an RDS file then mark that code block as eval=FALSE because it prevents the computer from having to re-run the ANN model each time the file is knitted while still being able to keep the entire project on one cohesive rmd and html. 

## ANN with 1 Hidden

Below is the code which generates an ANN model with hidden = 1.

```{r ann 1 hidden, eval=FALSE}


library(neuralnet)
library(caret)

ann_model_1hidden <- neuralnet(yyes ~ . , data = log_train, hidden = 1)
saveRDS(ann_model_1hidden , "ann_1hidden.rds")

# do 1 hidden, then 5, then 20 if possible


```

## ANN with 5 Hidden

Below is the code which generates an ANN model with hidden = 5.

```{r ann 5 hidden, eval=FALSE}

library(neuralnet)
library(caret)

ann_model_5hidden <- neuralnet(yyes ~ . , data = log_train, hidden = 5)
saveRDS(ann_model_5hidden , "ann_5hidden.rds")


```

## ANN with 20 Hidden

Below is the code which would have generated an ANN model with hidden = 20, had our computers had enough computing resources to build the train the model.

```{r ann 20 hidden, eval=FALSE}

library(neuralnet)
library(caret)

ann_model_20hidden <- neuralnet(yyes ~ . , data = log_train, hidden = 20)
saveRDS(ann_model_20hidden , "ann_20hidden.rds")



```


## ANN Prediction

Now that we have an ANN model with a hidden = 5, we can use that model to predict outcomes using out test data. This follows the same process as usual by first loading the RDS file into the code bloc, then using the predict function, and finally generating a confusion matrix to visualize the accuracy of our prediction against the real outcomes in the test data. 

```{r 5 hidden prediction}

hidden5_RDS <- readRDS("ann_5hidden.rds")
pred_5hidden <- predict(hidden5_RDS , log_test)
# we need to optimize the profits based on what we have for the threshold under binarypred_5hidden
binarypred_5hidden <- ifelse(pred_5hidden >= 0.5 , 1, 0)

library(caret)
confusionMatrix(as.factor(binarypred_5hidden) , as.factor(log_test$yyes) , positive = "1")

```

In order for the call center to maximize profits using this model, we need to determine the optimal threshold for creating the binary 0 and 1 prediction of if they should call or not. Like in the logistic regression, it is important that we do not only care about overall accuracy, but also the sensitivity vs the specificity. In this case we want to boost the sensitivity as much as we can without sacrificing too much specificity. This is because from a business standpoint, each successful call gains 6 dollars in revenue whereas each unsuccessful call only costs 1 dollar. Therefore, we care much more about catching as many 1s as we can in this model at the expense of picking up some false positives in our prediction. See the following section for code which optimizes the threshold.


### Optimizing Binary Prediction Threshold to Maximize Profits

As stated above, we need to code a for loop to find the threshold which will maximize profits for the call center. This process followed directly mirrors that in the logistic regression model. 

```{r}


library(caret)
confmat_ann <- confusionMatrix(as.factor(binarypred_5hidden) , as.factor(log_test$yyes), positive = "1")

confmat_ann
outcome_weights_ann <- matrix(
          c(0, 0,
          -1, 5),
          nrow = 2,
          byrow = TRUE
)


conf_mat_wg_ann <- sum(confmat_ann$table*outcome_weights_ann)
str(conf_mat_wg_ann)

outcome_ann <- data.frame(threshold = numeric(), profit = numeric())

threshold_list_ann <- seq(from = 0.01, to = 1, by = 0.01)

for (i in threshold_list_ann) {
  binarypred_5hidden <- ifelse(pred_5hidden >= i, 1, 0)
  confmat_ann <- confusionMatrix(as.factor(binarypred_5hidden) , as.factor(log_test$yyes), positive = "1")
  out <- sum(confmat_ann$table*outcome_weights_ann)
  nrow <- data.frame(threshold = i, profit = out)
  outcome_ann <- rbind(outcome_ann,nrow)
}

outcome_ann
ggplot(outcome_ann, aes(x = threshold, y = profit)) + 
  geom_line() + 
  labs(x = "Threshold", y = "Profit", title = "Profit per Treshold level")

# the optimal threshold looking at the table and plot is 0.11, so let's generate a prediction and confusionMatrix using said value

binarypred_5hidden <- ifelse(pred_5hidden >= 0.11 , 1, 0)

library(caret)
confusionMatrix(as.factor(binarypred_5hidden) , as.factor(log_test$yyes) , positive = "1")


```

Therefore, the optimal threshold for the ANN model prediction is 0.11. 


# Combining Models Together

```{r}

# summation function 
# if else statement of 2 or more to make binary prediction

# test combo model against actual test data outcomes






```




# Results and Analysis

we should look at the profit from each model individual and combined and compare to best -- remember that in the financial analysis we don't care so much about the opporunity cost, just the bottom line profit Rev - Cost of each call that would be hypothetically reported on a financial statement


- make sure to talk about favoring false pos over false neg because get 6 in revenue compared to 1 cost

# Conclusion

